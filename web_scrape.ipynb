{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping recipes\n",
    "#import urllib2\n",
    "import urllib.request as urllib2\n",
    "import json\n",
    "import collections, itertools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def scrap(dish, f, url, total):\n",
    "    \"\"\"Scrapes AllRecipes to get the recipes and images\"\"\"\n",
    "    try:\n",
    "        # Connect to the URL\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # Find all recipes on page\n",
    "        all_items = soup.find_all(\"div\", {'class': 'component card card__recipe card__facetedSearchResult'})\n",
    "\n",
    "        c = total\n",
    "        for item in all_items:\n",
    "            # Find div with the needed information (link to recipe and cover image)\n",
    "            top_item = item.find(\"div\", {'class': 'card__imageContainer'}\n",
    "            ).find(\"a\", {'class': 'card__titleLink manual-link-behavior elementFont__title margin-8-bottom'})\n",
    "            \n",
    "            dish_url = top_item['href']\n",
    "            url_title = top_item['title']\n",
    "            try:\n",
    "                # Finding the url to the image\n",
    "                img_url_ = top_item.find(\"div\", \n",
    "                {'class': ['component lazy-image lazy-image-udf aspect_1x1',\n",
    "                          'component lazy-image lazy-image-udf aspect_1x1 cache-only align-default',\n",
    "                          'component lazy-image lazy-image-udf aspect_1x1 cache-only',\n",
    "                          'component lazy-image lazy-image-udf aspect_1x1 align-default']}\n",
    "                )['data-src']\n",
    "            except:\n",
    "                # If it doesnt work, just move on to next url\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Try to save the image as a jpg, if not print error and move on\n",
    "                # Might get some HTTPS errors randomly here, maybe timeouts?\n",
    "                save_image(dish, img_url_, c)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(img_url_)\n",
    "                continue\n",
    "                \n",
    "            # go into the actual recipe link\n",
    "            page = requests.get(dish_url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "            #Fetch ingredients\n",
    "            ingredients = []\n",
    "            try:\n",
    "                web_ingredients = soup.find_all(\"li\", {'class': 'ingredients-item'})\n",
    "                for ing in web_ingredients:\n",
    "                    # Getting just the ingredient, ignoring the measurement. \"Value\" seems more standardized,\n",
    "                    # but less accurate\n",
    "                    rec_ing = ing.find('input', {'class': 'checkbox-list-input'})['data-ingredient']#['value']\n",
    "                    ingredients.append(rec_ing)\n",
    "            except:\n",
    "                # If fails, print out why\n",
    "                print(dish_url)\n",
    "                print(soup.find(\"ul\", {'class': 'ingredients-section'}))\n",
    "\n",
    "\n",
    "            #Fetch recipe instructions (not really needed but might be)\n",
    "            recipe_steps = []\n",
    "            web_recipe = soup.find('ul', {'class': 'instructions-section'})\n",
    "            if web_recipe is not None:\n",
    "                web_recipe = web_recipe.find_all('p')\n",
    "                for rec in web_recipe:\n",
    "                    recipe_steps.append(rec.text)\n",
    "\n",
    "            #Write recipe to text file\n",
    "            result = str(dish) + \",\" + str(dish_url) + \",\" + str(ingredients) + \",\" + str(recipe_steps) + \"\\n\"\n",
    "            f.write(result)\n",
    "\n",
    "            c += 1\n",
    "\n",
    "    except urllib2.HTTPError:\n",
    "        return(\"wrong url\")\n",
    "    return c\n",
    "\n",
    "\n",
    "def save_image(dish, image_url, num):\n",
    "    #save image to file \n",
    "    resp = requests.get(image_url, stream=True)\n",
    "    if not os.path.exists(\"data/\" + dish):\n",
    "        os.makedirs(\"data/\" + dish)\n",
    "    local_file = open(\"data/\" + dish + \"/\" + str(num) + \".jpg\", 'wb')\n",
    "    resp.raw.decode_content = True\n",
    "    shutil.copyfileobj(resp.raw, local_file)\n",
    "    del resp\n",
    "    return\n",
    "\n",
    "\n",
    "def main(page_count):\n",
    "    #Take food types from classes.txt and search AllRecipes for links\n",
    "    #Pagecount is how many pages to pull, each page has 25 results I think\n",
    "    file = open(\"classes.txt\", \"r\")\n",
    "    f = open('Recipes.txt', 'w', encoding='utf-8')\n",
    "    all_classes = file.read().split()\n",
    "    count = 0\n",
    "    for dish in all_classes:\n",
    "        total = 0\n",
    "        count += 1\n",
    "        print(dish)\n",
    "        # search the url for recipes\n",
    "        for i in range(1, page_count+1):\n",
    "            url = \"https://www.allrecipes.com/search/results/?search=\" + '%20'.join(dish.split('_')\n",
    "                                                )  + \"&sort=re\" + \"&page=\" + str(i) \n",
    "            total = scrap(dish, f, url, total)\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /img/icons/generic-recipe.svg\n",
    "# component lazy-image lazy-image-udf aspect_1x1 cache-only align-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(page_count = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
